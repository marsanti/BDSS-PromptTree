import random
import numpy as np
from .utils import split_by_test, gini, class_distribution
from .distances import DELTA_SET

# Default callbacks for the tree functions
def fp_default(
        B: list[int],
        next_start: int,
        X: list, 
        Y: list, 
        window_lengths: tuple=(5, 10, 20)
) -> list[tuple[int, list[int, int]]]:
    '''
    Promptness function: Determines which intervals in the time series
    to consider for testing at each node.

    Parameters
    ----------
        B : list of int
            Set of possible start indices for candidate intervals.
        next_start : int
            Additional start index to consider for candidate intervals.
        X : list
            List of input samples, each sample is a list/array of shape (channels, T).
        Y : list
            List of labels corresponding to X.
        window_lengths : tuple of int
            Possible window lengths to use for candidate intervals.

    Returns
    -------
        list of candidates
            Each tuple is (channel_index, [start, end])
    '''
    # Get number of channels from the first sample
    num_channels = len(X[0]) 
    min_T = min(len(xi[0]) for xi in X) # !!! ASSUMPTION !!! All channels have same length

    starts = sorted(set(B) | {next_start})
    cands = []
    
    # Iterate over all channels, not just channel 0
    for c in range(num_channels):
        for b in starts:
            for w in window_lengths:
                e = b + w
                if e <= min_T:
                    cands.append((c, [b, e])) # Propose test for channel c

    return cands


def fs_default(
    X: list, 
    Y: list, 
    candidate_intervals: list[tuple[int, list[int]]], 
    deltas: tuple[str, ...] = ("l2",), 
    K_refs: int = 5, 
    eps_percentiles: tuple[int, ...] = (25, 50, 75),
    seed: int = 0
) -> list[tuple[int, np.ndarray, float, list[int], str]]:
    """
    Sampling Function (fs): Generates a set of candidate tests based on
    the intervals selected by fp.

    Parameters
    ----------
    X : list
        List of input samples, where each sample is a list or array of shape (channels, T).
    Y : list
        List of labels corresponding to X.
    candidate_intervals : list of tuples
        Each tuple is (channel_index, [start, end]) specifying the interval to consider.
    deltas : tuple of str, optional
        Names of distance functions to use (default: ("l2",)).
    K_refs : int, optional
        Number of reference samples to use for threshold generation (default: 5).
    eps_percentiles : tuple of int, optional
        Percentiles of distances to use as thresholds (default: (25, 50, 75)).
    seed : int, optional
        Random seed for reproducibility (default: 0).

    Returns
    -------
    list of tuples
        Each tuple is (channel_index, x_ref, eps, [start, end], delta_name), representing a candidate test.
    """
    rng = np.random.default_rng(seed)
    tests = []
    ref_idx = rng.choice(len(X), size=min(K_refs, len(X)), replace=False)
    for c, (b, e) in candidate_intervals:
        for ridx in ref_idx:
            x_ref = np.asarray(X[ridx][c][b:e])
            for delta_name in deltas:
                delta_func = DELTA_SET[delta_name]
                dists = [
                    delta_func(np.asarray(x[c][b:e]), x_ref)
                    for x in X
                    if len(x[c]) >= e
                ]
                if not dists:
                    continue
                for q in eps_percentiles:
                    eps = float(np.percentile(dists, q))
                    tests.append((c, x_ref, eps, [b, e], delta_name))
    return tests


def fo_default(
    X: list,
    Y: list,
    candidate_tests: list[tuple]
) -> tuple[tuple | None, float]:
    """
    Optimization Function: selects the optimal test from the candidates
    generated by fs. This determines the split at each node.

    Args:
        X (list): The list of feature vectors.
        Y (list): The list of corresponding labels.
        candidate_tests (list[tuple]): A list of candidate tests, where each test is a tuple
            containing (c, x_ref, eps, (b, e), delta_name).

    Returns:
        tuple[tuple | None, float]: A tuple containing or the best candidate test as a tuple (c, x_ref, eps, [b, e], delta_name), or None if no valid split is found and The best Gini impurity gain as a float.
    """
    best = None
    best_gain = 0.0
    impurity_parent = gini(Y)
    for c, x_ref, eps, (b, e), delta_name in candidate_tests:
        delta_func = DELTA_SET[delta_name]
        (X_t, Y_t), (X_f, Y_f) = split_by_test(X, Y, (c, x_ref, b, e, delta_func, eps))
        if not Y_t or not Y_f:
            continue
        w = len(Y_t) / len(Y)
        gain = impurity_parent - (w * gini(Y_t) + (1 - w) * gini(Y_f))
        if gain > best_gain:
            best_gain = gain
            best = (c, x_ref, eps, [b, e], delta_name)
    return best, best_gain


def fc_default(X: list, Y: list) -> dict:
    """
    Computes and returns the class distribution of the target variable Y.

    Args:
        X (list): The list of feature vectors.
        Y (list): The list of corresponding labels.

    Returns:
        dict: A dictionary representing the distribution of classes in Y, 
                where keys are class labels and values are their respective counts or proportions.
    """
    return class_distribution(Y)


def fe_default(
    Path: list, 
    X: list, 
    Y: list, 
    depth: int, 
    max_depth: int = 12, 
    min_samples: int = 5
) -> bool:
    """
    Stopping Criterion: Determines when to stop expanding the tree 
    and create a leaf node instead.

    Args:
        Path (list): The path taken to reach the current node.
        X (list): The list of feature vectors at the current node.
        Y (list): The list of corresponding labels at the current node.
        depth (int): The current depth of the node in the tree.
        max_depth (int, optional): The maximum allowed depth for the tree (default: 12).
        min_samples (int, optional): The minimum number of samples required to split (default: 5).

    Returns:
        bool: True if the node should stop splitting (become a leaf), False otherwise.
    """
    if depth >= max_depth or len(Y) < min_samples:
        return True
    # pure node
    if len(set(Y)) == 1:
        return True
    return False

def fo_unsupervised_random(X, Y, candidate_tests):
    """Randomly selects a valid split test."""
    # Filter for tests that actually split the data
    valid_tests = []
    for test in candidate_tests:
        c, x_ref, eps, (b, e), delta_name = test
        delta_func = DELTA_SET[delta_name]
        (X_t, Y_t), (X_f, Y_f) = split_by_test(X, None, (c, x_ref, b, e, delta_func, eps)) # Pass Y=None
        if len(X_t) > 0 and len(X_f) > 0:
            valid_tests.append(test)

    if not valid_tests:
        return None, 0.0 # No valid split found

    # Select one valid test randomly
    best_test = random.choice(valid_tests)
    return best_test, 1.0 # Return dummy gain


def fe_unsupervised_default(Path, X, Y, depth, max_depth=15): # Example max_depth
     """Stopping criterion for isolation."""
     if depth >= max_depth or len(X) <= 1:
         return True
     return False